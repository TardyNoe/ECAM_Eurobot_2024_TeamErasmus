#!/usr/bin/env python

import rospy
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
import cv2
import numpy as np
import time
import threading

mtx1 = np.array([[899.9407098052037, 0.0, 935.8491370923285], [0.0, 900.2176117746629, 523.0356982676464], [0.0, 0.0, 1.0]])
dist1 = np.array([[-0.28804628309873526, 0.08216048075928635, 0.0005545901850384366, 0.00015312879975407738, -0.010170047195160393]])
h, w = (1080, 1920)
newcameramtx1, roi1 = cv2.getOptimalNewCameraMatrix(mtx1, dist1, (w, h), 1, (w, h))
x1, y1, w1, h1 = roi1
mapx1, mapy1 = cv2.initUndistortRectifyMap(mtx1, dist1, None, newcameramtx1, (w, h), 5)
ajust = 250

mtx2=np.array([[1714.7738644259807, 0.0, 914.7312181318101], [0.0, 1712.8518403517126, 635.7587939782419], [0.0, 0.0, 1.0]])
dist2=np.array([[-0.41367203061960334, 0.12275820841292197, 0.0006816171773578168, -0.0005819945024961491, 0.11998319032229471]])
h, w = (1080, 1920)
newcameramtx2, roi2 = cv2.getOptimalNewCameraMatrix(mtx2, dist2, (w, h), 1, (w, h))
mapx2, mapy2 = cv2.initUndistortRectifyMap(mtx2, dist2, None, newcameramtx2, (w, h), 5)

def findCorrespondance(frame1,frame2):
    dictionary = cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_50)
    detector_params = cv2.aruco.DetectorParameters_create()
    corners1, ids1, rejected_img_points1 = cv2.aruco.detectMarkers(frame1, dictionary, parameters=detector_params)
    corners2, ids2, rejected_img_points2 = cv2.aruco.detectMarkers(frame2, dictionary, parameters=detector_params)
    points1 = [[0,0,0,0],[0,0,0,0]]
    points2 = [[0,0,0,0],[0,0,0,0]]

    if ids1 is not None:
            for i in range(len(corners1)):
                if(ids1[i]==23):
                    points1[0][1] = int(corners1[i][0][1][0])
                    points1[0][2] = int(corners1[i][0][2][0])
                    points1[1][1] = int(corners1[i][0][1][1])
                    points1[1][2] = int(corners1[i][0][2][1])
                if(ids1[i]==22):
                    points1[0][0] = int(corners1[i][0][0][0])
                    points1[0][3] = int(corners1[i][0][3][0])
                    points1[1][0] = int(corners1[i][0][0][1])
                    points1[1][3] = int(corners1[i][0][3][1])
                
    if ids2 is not None:
            for i in range(len(corners2)):
                for c in range(4):
                    if(ids2[i]==20):
                        points2[0][1] = int(corners2[i][0][3][0])
                        points2[0][2] = int(corners2[i][0][0][0])
                        points2[1][1] = int(corners2[i][0][3][1])
                        points2[1][2] = int(corners2[i][0][0][1])
                    if(ids2[i]==21):
                        points2[0][0] = int(corners2[i][0][2][0])
                        points2[0][3] = int(corners2[i][0][1][0])
                        points2[1][0] = int(corners2[i][0][2][1])
                        points2[1][3] = int(corners2[i][0][1][1])
                    
    w1 = [[0.518,1.477,1.477,0.518],[2.374,2.374,2.4732,2.4732]]
    Mat1 = np.array([
        [w1[0][0],w1[1][0],1,0,0,0,-points1[0][0]*w1[0][0],-points1[0][0]*w1[1][0]],
        [0,0,0,w1[0][0],w1[1][0],1,-points1[1][0]*w1[0][0],-points1[1][0]*w1[1][0]],
        [w1[0][1],w1[1][1],1,0,0,0,-points1[0][1]*w1[0][1],-points1[0][1]*w1[1][1]],
        [0,0,0,w1[0][1],w1[1][1],1,-points1[1][1]*w1[0][1],-points1[1][1]*w1[1][1]],
        [w1[0][2],w1[1][2],1,0,0,0,-points1[0][2]*w1[0][2],-points1[0][2]*w1[1][2]],
        [0,0,0,w1[0][2],w1[1][2],1,-points1[1][2]*w1[0][2],-points1[1][2]*w1[1][2]],
        [w1[0][3],w1[1][3],1,0,0,0,-points1[0][3]*w1[0][3],-points1[0][3]*w1[1][3]],
        [0,0,0,w1[0][3],w1[1][3],1,-points1[1][3]*w1[0][3],-points1[1][3]*w1[1][3]],
    ])
    vect1 = np.array([points1[0][0],points1[1][0],points1[0][1],points1[1][1],points1[0][2],points1[1][2],points1[0][3],points1[1][3]])
    invMat1 = np.linalg.inv(np.matrix(Mat1))
    M1 = invMat1 @ vect1
    M1 = np.array(M1)[0]

    w2 = [[1.477,0.518,0.518,1.477],[0.622,0.622,0.524,0.524]]

    Mat2 = np.array([
        [w2[0][0],w2[1][0],1,0,0,0,-points2[0][0]*w2[0][0],-points2[0][0]*w2[1][0]],
        [0,0,0,w2[0][0],w2[1][0],1,-points2[1][0]*w2[0][0],-points2[1][0]*w2[1][0]],
        [w2[0][1],w2[1][1],1,0,0,0,-points2[0][1]*w2[0][1],-points2[0][1]*w2[1][1]],
        [0,0,0,w2[0][1],w2[1][1],1,-points2[1][1]*w2[0][1],-points2[1][1]*w2[1][1]],
        [w2[0][2],w2[1][2],1,0,0,0,-points2[0][2]*w2[0][2],-points2[0][2]*w2[1][2]],
        [0,0,0,w2[0][2],w2[1][2],1,-points2[1][2]*w2[0][2],-points2[1][2]*w2[1][2]],
        [w2[0][3],w2[1][3],1,0,0,0,-points2[0][3]*w2[0][3],-points2[0][3]*w2[1][3]],
        [0,0,0,w2[0][3],w2[1][3],1,-points2[1][3]*w2[0][3],-points2[1][3]*w2[1][3]],
    ])
    vect2 = np.array([points2[0][0],points2[1][0],points2[0][1],points2[1][1],points2[0][2],points2[1][2],points2[0][3],points2[1][3]])
    invMat2 = np.linalg.inv(np.matrix(Mat2))
    M2 = invMat2 @ vect2
    M2 = np.array(M2)[0]
    t = time.time()
    M2_matrix = np.array([[M2[0], M2[1], M2[2]],
                        [M2[3], M2[4], M2[5]],
                        [M2[6], M2[7], 1]])
    M1_matrix = np.array([[M1[0], M1[1], M1[2]],
                        [M1[3], M1[4], M1[5]],
                        [M1[6], M1[7], 1]])

    correspondance1 = np.zeros((600, 400,2), dtype=np.uint32)
    correspondance2 = np.zeros((600, 400,2), dtype=np.uint32)


    for y in range(600):
        for x in range(400):
            pixel = np.array([x / 200, y / 200, 1])
            transformed_pixel = np.dot(M2_matrix, pixel)
            transformed_pixel /= transformed_pixel[2]
            correspondance1[y, x] = [int(transformed_pixel[1]), int(transformed_pixel[0])]
    for y in range(600):
        for x in range(400):
            pixel = np.array([x / 200, y / 200, 1])
            transformed_pixel = np.dot(M1_matrix, pixel)
            transformed_pixel /= transformed_pixel[2]
            correspondance2[y, x] = [int(transformed_pixel[1]), int(transformed_pixel[0])]
    return correspondance1,correspondance2

def computeImage(frame1,frame2,correspondance1,correspondance2):
    if correspondance1 is not None or correspondance2 is not None:
        y_indices1 = correspondance1[:, :, 0]
        x_indices1 = correspondance1[:, :, 1]
        y_indices1 = np.clip(y_indices1, 0, frame2.shape[0] - 1)
        x_indices1 = np.clip(x_indices1, 0, frame2.shape[1] - 1)

        y_indices2 = correspondance2[:, :, 0]
        x_indices2 = correspondance2[:, :, 1]
        y_indices2 = np.clip(y_indices2, 0, frame1.shape[0] - 1)
        x_indices2 = np.clip(x_indices2, 0, frame1.shape[1] - 1)

        result1 = frame2[y_indices1, x_indices1]
        result2 = frame1[y_indices2, x_indices2]
        return np.vstack((result1[:300], result2[300:]))
    else:
        frame1 = cv2.resize(frame1, (300,300), interpolation = cv2.INTER_AREA)
        frame2 = cv2.resize(frame2, (300,300), interpolation = cv2.INTER_AREA)
        return np.vstack((frame1, frame2))
class CameraThread(threading.Thread):
    def __init__(self, camID, callback):
        threading.Thread.__init__(self)
        self.camID = camID
        self.callback = callback

    def run(self):
        cap = cv2.VideoCapture(self.camID)
        cap.set(3, 1920)
        cap.set(4, 1080)
        try:
            while True:
                ret, frame = cap.read()
                if ret:
                    self.callback(frame)
        except:
            cap.release()
class ImageProcessor:
    def __init__(self):
        self.bridge = CvBridge()
        self.image1 = None
        self.image2 = None

        rospy.init_node('image_processor', anonymous=True)
        self.image_pub = rospy.Publisher("mask", Image, queue_size=1)
    def camera_callback1(self, frame):
        self.image1 = frame

    def camera_callback2(self, frame):
        self.image2 = frame

    def process_images(self):
        correspondance1,correspondance2 = None,None
        calib = False
        RefImage = None
        tstart = time.time()
        result = None
        result2 = None
        while not rospy.is_shutdown():
            if self.image1 is not None and self.image2 is not None:
                image1undist  = cv2.remap(self.image1 , mapx1, mapy1, cv2.INTER_LINEAR)
                image1undist  = image1undist [:, x1 - ajust: x1 + w1 + ajust]
                image2undist  = cv2.remap(self.image2 , mapx2, mapy2, cv2.INTER_LINEAR)
                blue, green, red = cv2.split(image2undist)
                image2undist = cv2.merge((red, green, blue))
                if calib == False and time.time()-tstart>20:
                    print("calib")
                    calib = True
                    correspondance1,correspondance2 = findCorrespondance(image1undist,image2undist)
                    RefImage = computeImage(image1undist,image2undist,correspondance1,correspondance2)
                    RefImage = cv2.cvtColor(RefImage, cv2.COLOR_BGR2GRAY) 
                    RefImage = cv2.GaussianBlur(RefImage, (9, 9), 2)
                processed_image = computeImage(image1undist,image2undist,correspondance1,correspondance2) 
                #processed_image = cv2.resize(processed_image, (25,25), interpolation = cv2.INTER_AREA)
                #processed_image = cv2.cvtColor(processed_image, cv2.COLOR_BGR2GRAY)
                if calib == True and RefImage is not None:
                    grayscale_image2 = cv2.cvtColor(processed_image, cv2.COLOR_BGR2GRAY)
                    blurred_image2 = cv2.GaussianBlur(grayscale_image2, (9, 9), 2)
                    difference_image = cv2.absdiff(RefImage, blurred_image2)
                    threshold_method = cv2.THRESH_BINARY
                    _, result = cv2.threshold(difference_image, 50, 255, threshold_method)
                    result = cv2.dilate(result, np.ones((5, 5), np.uint8), iterations=1)
                    #result2 = cv2.bitwise_and(processed_image, processed_image, mask=result)
                    #hsv_image = cv2.cvtColor(result2, cv2.COLOR_BGR2HSV)
                    #lower_hsv = np.array([157, 0.36*255, 0.4*255], dtype=np.uint8)  # lower: hsv(157, 36%, 40%)
                    #upper_hsv = np.array([305, 1*255, 1*255], dtype=np.uint8)  # upper: hsv(305, 100%, 100%)
                    #result2 = cv2.inRange(hsv_image, lower_hsv, upper_hsv)
                    contours, _ = cv2.findContours(result, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    print(time.time()-tstart)
                    tstart = time.time()
                    for contour in contours:
                        area = cv2.contourArea(contour)
                        M = cv2.moments(contour)
                        if M["m00"] != 0:
                            cX = int(M["m10"] / M["m00"])
                            cY = int(M["m01"] / M["m00"])
                            print(cX,cY)
                try:
                    processed_image_msg = self.bridge.cv2_to_imgmsg(result, "mono8")
                    self.image_pub.publish(processed_image_msg)
                except KeyboardInterrupt:
                    break
                except Exception as e:
                    print(e)

if __name__ == '__main__':
    try:
        processor = ImageProcessor()
        thread1 = CameraThread(0, processor.camera_callback1)
        thread2 = CameraThread(2, processor.camera_callback2)
        thread1.start()
        thread2.start()
        processor.process_images()
    except rospy.ROSInterruptException:
        pass
